{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a49179",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:04.980141Z",
     "iopub.status.busy": "2024-05-21T13:57:04.979857Z",
     "iopub.status.idle": "2024-05-21T13:57:11.844393Z",
     "shell.execute_reply": "2024-05-21T13:57:11.843621Z"
    },
    "papermill": {
     "duration": 6.874461,
     "end_time": "2024-05-21T13:57:11.846738",
     "exception": false,
     "start_time": "2024-05-21T13:57:04.972277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = '../../inputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce5f25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.860558Z",
     "iopub.status.busy": "2024-05-21T13:57:11.860022Z",
     "iopub.status.idle": "2024-05-21T13:57:11.865330Z",
     "shell.execute_reply": "2024-05-21T13:57:11.864468Z"
    },
    "papermill": {
     "duration": 0.014627,
     "end_time": "2024-05-21T13:57:11.867779",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.853152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Start Time (UTC): 2024-05-23 00:33:50.432665\n",
      "Notebook Start Time (KST): 2024-05-23 09:33:50.432665\n"
     ]
    }
   ],
   "source": [
    "start_time_utc = datetime.datetime.now()\n",
    "print(f'Notebook Start Time (UTC): {start_time_utc}')\n",
    "\n",
    "start_time_kst = start_time_utc + datetime.timedelta(hours=9)\n",
    "print(f\"Notebook Start Time (KST): {start_time_kst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d68128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.882190Z",
     "iopub.status.busy": "2024-05-21T13:57:11.881943Z",
     "iopub.status.idle": "2024-05-21T13:57:11.904318Z",
     "shell.execute_reply": "2024-05-21T13:57:11.903518Z"
    },
    "papermill": {
     "duration": 0.031303,
     "end_time": "2024-05-21T13:57:11.906166",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.874863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "                if isnull > 0.7:\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    # Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "        expr_var = [pl.var(col).alias(f\"var_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max + expr_last + expr_mean \n",
    "\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max + expr_last + expr_mean \n",
    "\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        # expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        return expr_max + expr_last  # +expr_count\n",
    "\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return expr_max + expr_last\n",
    "\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return expr_max + expr_last\n",
    "\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a8adac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.919186Z",
     "iopub.status.busy": "2024-05-21T13:57:11.918945Z",
     "iopub.status.idle": "2024-05-21T13:57:11.925715Z",
     "shell.execute_reply": "2024-05-21T13:57:11.924942Z"
    },
    "papermill": {
     "duration": 0.01535,
     "end_time": "2024-05-21T13:57:11.927556",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.912206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0973d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.940767Z",
     "iopub.status.busy": "2024-05-21T13:57:11.940111Z",
     "iopub.status.idle": "2024-05-21T13:57:11.947424Z",
     "shell.execute_reply": "2024-05-21T13:57:11.946567Z"
    },
    "papermill": {
     "duration": 0.015758,
     "end_time": "2024-05-21T13:57:11.949285",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.933527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from polars import selectors as cs\n",
    "\n",
    "\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    display(df_base.select(cs.ends_with('D')))\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e0e7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.962261Z",
     "iopub.status.busy": "2024-05-21T13:57:11.962031Z",
     "iopub.status.idle": "2024-05-21T13:57:11.974290Z",
     "shell.execute_reply": "2024-05-21T13:57:11.973470Z"
    },
    "papermill": {
     "duration": 0.020995,
     "end_time": "2024-05-21T13:57:11.976224",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.955229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ab93d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:57:11.989270Z",
     "iopub.status.busy": "2024-05-21T13:57:11.989016Z",
     "iopub.status.idle": "2024-05-21T13:59:25.037211Z",
     "shell.execute_reply": "2024-05-21T13:59:25.036171Z"
    },
    "papermill": {
     "duration": 133.057601,
     "end_time": "2024-05-21T13:59:25.039827",
     "exception": false,
     "start_time": "2024-05-21T13:57:11.982226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT            = Path(ROOT)\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbf7854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:59:25.054121Z",
     "iopub.status.busy": "2024-05-21T13:59:25.053824Z",
     "iopub.status.idle": "2024-05-21T13:59:46.055615Z",
     "shell.execute_reply": "2024-05-21T13:59:46.054492Z"
    },
    "papermill": {
     "duration": 21.011421,
     "end_time": "2024-05-21T13:59:46.057792",
     "exception": false,
     "start_time": "2024-05-21T13:59:25.046371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_526_659, 123)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>assignmentdate_4955616D</th><th>birthdate_574D</th><th>dateofbirth_337D</th><th>dateofbirth_342D</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>datefirstoffer_1144D</th><th>datelastinstal40dpd_247D</th><th>datelastunpaid_3546854D</th><th>dtlastpmtallstes_4499206D</th><th>firstclxcampaign_1125D</th><th>firstdatedue_489D</th><th>lastactivateddate_801D</th><th>lastapplicationdate_877D</th><th>lastapprdate_640D</th><th>lastdelinqdate_224D</th><th>lastrejectdate_50D</th><th>lastrepayingdate_696D</th><th>maxdpdinstldate_3546855D</th><th>payvacationpostpone_4187118D</th><th>validfrom_1069D</th><th>max_approvaldate_319D</th><th>max_creationdate_885D</th><th>max_dateactivated_425D</th><th>max_dtlastpmt_581D</th><th>max_dtlastpmtallstes_3545839D</th><th>max_employedfrom_700D</th><th>max_firstnonzeroinstldate_307D</th><th>last_approvaldate_319D</th><th>last_creationdate_885D</th><th>last_dateactivated_425D</th><th>last_dtlastpmt_581D</th><th>last_dtlastpmtallstes_3545839D</th><th>last_employedfrom_700D</th><th>&hellip;</th><th>mean_numberofoverdueinstlmaxdat_641D</th><th>mean_overdueamountmax2date_1002D</th><th>mean_overdueamountmax2date_1142D</th><th>mean_refreshdate_3813885D</th><th>max_contractdate_551D</th><th>max_contractmaturitydate_151D</th><th>max_lastupdate_260D</th><th>last_contractdate_551D</th><th>last_contractmaturitydate_151D</th><th>last_lastupdate_260D</th><th>mean_contractdate_551D</th><th>mean_contractmaturitydate_151D</th><th>mean_lastupdate_260D</th><th>max_birth_259D</th><th>max_birthdate_87D</th><th>max_empl_employedfrom_271D</th><th>last_birth_259D</th><th>last_birthdate_87D</th><th>last_empl_employedfrom_271D</th><th>mean_birth_259D</th><th>mean_birthdate_87D</th><th>mean_empl_employedfrom_271D</th><th>max_contractenddate_991D</th><th>max_openingdate_313D</th><th>last_contractenddate_991D</th><th>last_openingdate_313D</th><th>mean_contractenddate_991D</th><th>mean_openingdate_313D</th><th>max_openingdate_857D</th><th>last_openingdate_857D</th><th>mean_openingdate_857D</th><th>max_pmts_date_1107D</th><th>last_pmts_date_1107D</th><th>mean_pmts_date_1107D</th><th>max_empls_employedfrom_796D</th><th>last_empls_employedfrom_796D</th><th>mean_empls_employedfrom_796D</th></tr><tr><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>&hellip;</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td><td>date</td></tr></thead><tbody><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1986-07-01</td><td>null</td><td>2017-09-15</td><td>null</td><td>null</td><td>null</td><td>1986-07-01</td><td>null</td><td>2017-09-15</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1957-08-01</td><td>null</td><td>2008-10-29</td><td>null</td><td>null</td><td>null</td><td>1957-08-01</td><td>null</td><td>2008-10-29</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2013-04-03</td><td>null</td><td>null</td><td>2013-04-03</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2013-04-03</td><td>null</td><td>null</td><td>null</td><td>2010-02-15</td><td>2013-05-04</td><td>null</td><td>2013-04-03</td><td>null</td><td>null</td><td>null</td><td>2010-02-15</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1974-12-01</td><td>null</td><td>2010-02-15</td><td>null</td><td>null</td><td>null</td><td>1974-12-01</td><td>null</td><td>2010-02-15</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-07</td><td>null</td><td>null</td><td>2019-01-07</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-07</td><td>null</td><td>null</td><td>null</td><td>2018-05-15</td><td>2019-02-07</td><td>null</td><td>2019-01-07</td><td>null</td><td>null</td><td>null</td><td>2018-05-15</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1993-08-01</td><td>null</td><td>2018-05-15</td><td>null</td><td>null</td><td>null</td><td>1993-08-01</td><td>null</td><td>2018-05-15</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-08</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-01-08</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019-02-08</td><td>null</td><td>2019-01-08</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1994-01-01</td><td>null</td><td>2014-12-15</td><td>null</td><td>null</td><td>null</td><td>1994-01-01</td><td>null</td><td>2014-12-15</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>null</td><td>null</td><td>2018-01-11</td><td>null</td><td>1960-01-01</td><td>null</td><td>null</td><td>null</td><td>2020-10-19</td><td>2013-02-19</td><td>null</td><td>2016-09-15</td><td>null</td><td>2016-05-09</td><td>2007-07-13</td><td>2019-10-16</td><td>2019-10-09</td><td>2019-10-09</td><td>2016-09-15</td><td>2017-11-30</td><td>null</td><td>2016-08-15</td><td>null</td><td>null</td><td>2019-10-09</td><td>2019-10-09</td><td>2019-10-16</td><td>2020-10-08</td><td>2020-10-08</td><td>2015-01-15</td><td>2019-11-08</td><td>2007-06-12</td><td>2007-06-12</td><td>2007-06-19</td><td>null</td><td>null</td><td>1998-08-15</td><td>&hellip;</td><td>null</td><td>2015-11-17</td><td>null</td><td>2020-05-14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1960-01-01</td><td>null</td><td>null</td><td>1960-01-01</td><td>null</td><td>null</td><td>1960-01-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>2005-06-15</td><td>null</td><td>1950-11-01</td><td>null</td><td>null</td><td>null</td><td>2020-10-19</td><td>2016-03-01</td><td>null</td><td>2020-05-30</td><td>null</td><td>2016-03-01</td><td>2015-08-17</td><td>2019-10-07</td><td>2019-09-30</td><td>2019-09-30</td><td>2020-05-30</td><td>null</td><td>null</td><td>2020-05-30</td><td>null</td><td>null</td><td>2019-09-30</td><td>2019-09-30</td><td>2019-10-07</td><td>2020-09-28</td><td>2020-10-13</td><td>null</td><td>2019-10-30</td><td>2015-07-17</td><td>2015-07-17</td><td>2015-07-17</td><td>2016-12-17</td><td>2016-12-17</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>2020-05-14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1950-11-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1950-11-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td><td>1977-08-01</td><td>null</td><td>null</td><td>null</td><td>2020-10-19</td><td>null</td><td>null</td><td>2019-03-16</td><td>2019-10-21</td><td>null</td><td>2018-10-16</td><td>2019-08-23</td><td>2020-08-21</td><td>2019-08-19</td><td>2019-03-16</td><td>null</td><td>null</td><td>2019-02-16</td><td>null</td><td>null</td><td>2019-08-19</td><td>2020-08-21</td><td>2019-08-23</td><td>2019-10-21</td><td>2019-10-21</td><td>2018-02-01</td><td>2020-09-21</td><td>2018-09-16</td><td>2018-09-16</td><td>2018-09-24</td><td>2019-03-19</td><td>2019-03-19</td><td>2018-02-01</td><td>&hellip;</td><td>2020-05-13</td><td>null</td><td>2020-05-13</td><td>2020-05-14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1977-08-01</td><td>null</td><td>null</td><td>1977-08-01</td><td>null</td><td>null</td><td>1977-08-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>2008-02-15</td><td>null</td><td>1950-02-01</td><td>null</td><td>null</td><td>null</td><td>2020-10-17</td><td>2014-04-30</td><td>null</td><td>2018-01-15</td><td>null</td><td>2017-06-21</td><td>2013-07-29</td><td>2019-12-23</td><td>2019-12-18</td><td>2019-12-18</td><td>2018-01-15</td><td>2013-06-29</td><td>null</td><td>2015-08-15</td><td>null</td><td>null</td><td>2019-12-18</td><td>2019-12-18</td><td>2019-12-23</td><td>2019-12-17</td><td>2020-10-09</td><td>null</td><td>2020-01-18</td><td>null</td><td>2013-06-29</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>2015-06-20</td><td>null</td><td>2020-05-14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1950-02-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1950-02-01</td><td>null</td><td>null</td><td>2018-05-28</td><td>2015-05-29</td><td>null</td><td>2014-08-18</td><td>2018-05-28</td><td>2015-01-07</td><td>2015-05-29</td><td>2014-08-18</td><td>2015-01-07</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>null</td><td>2000-08-22</td><td>null</td><td>1948-04-01</td><td>null</td><td>null</td><td>null</td><td>2020-10-19</td><td>null</td><td>null</td><td>2019-09-01</td><td>2020-09-15</td><td>null</td><td>2019-09-01</td><td>2020-06-23</td><td>2020-06-21</td><td>2020-06-21</td><td>2019-09-01</td><td>null</td><td>null</td><td>2019-09-01</td><td>null</td><td>null</td><td>2020-06-21</td><td>2020-06-21</td><td>2020-06-23</td><td>2020-08-02</td><td>2020-10-19</td><td>null</td><td>2020-07-21</td><td>2019-08-01</td><td>2019-08-01</td><td>2019-08-20</td><td>2020-08-02</td><td>2020-08-02</td><td>null</td><td>&hellip;</td><td>null</td><td>2016-11-02</td><td>null</td><td>2020-05-14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1948-04-01</td><td>null</td><td>null</td><td>1948-04-01</td><td>null</td><td>null</td><td>1948-04-01</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_526_659, 123)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ assignmen ┆ assignmen ┆ assignmen ┆ birthdate ┆ … ┆ mean_pmts ┆ max_empls ┆ last_empl ┆ mean_emp │\n",
       "│ tdate_238 ┆ tdate_452 ┆ tdate_495 ┆ _574D     ┆   ┆ _date_110 ┆ _employed ┆ s_employe ┆ ls_emplo │\n",
       "│ D         ┆ 7235D     ┆ 5616D     ┆ ---       ┆   ┆ 7D        ┆ from_796D ┆ dfrom_796 ┆ yedfrom_ │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ date      ┆   ┆ ---       ┆ ---       ┆ D         ┆ 796D     │\n",
       "│ date      ┆ date      ┆ date      ┆           ┆   ┆ date      ┆ date      ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ date      ┆ date     │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ null      ┆ null      ┆ 2018-01-1 ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│           ┆           ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ null      ┆ null      ┆ 2005-06-1 ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│           ┆           ┆ 5         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ null      ┆ null      ┆ null      ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ null      ┆ null      ┆ 2008-02-1 ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│           ┆           ┆ 5         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ null      ┆ null      ┆ 2000-08-2 ┆ null      ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│           ┆           ┆ 2         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 861)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float64    659\n",
       "object     192\n",
       "int64        7\n",
       "int8         2\n",
       "bool         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = feature_eng(**data_store)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store\n",
    "\n",
    "display(df_train.to_pandas().dtypes.value_counts())\n",
    "\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c25d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T13:59:46.071838Z",
     "iopub.status.busy": "2024-05-21T13:59:46.071529Z",
     "iopub.status.idle": "2024-05-21T14:01:02.905726Z",
     "shell.execute_reply": "2024-05-21T14:01:02.904904Z"
    },
    "papermill": {
     "duration": 76.843727,
     "end_time": "2024-05-21T14:01:02.907958",
     "exception": false,
     "start_time": "2024-05-21T13:59:46.064231",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, cat_cols = to_pandas(df_train)\n",
    "# df_train = reduce_mem_usage(df_train)\n",
    "# print(\"train data shape:\\t\", df_train.shape)\n",
    "# nums=df_train.select_dtypes(exclude='category').columns\n",
    "# from itertools import combinations, permutations\n",
    "# #df_train=df_train[nums]\n",
    "# nans_df = df_train[nums].isna()\n",
    "# nans_groups={}\n",
    "# for col in nums:\n",
    "#     cur_group = nans_df[col].sum()\n",
    "#     try:\n",
    "#         nans_groups[cur_group].append(col)\n",
    "#     except:\n",
    "#         nans_groups[cur_group]=[col]\n",
    "# del nans_df; x=gc.collect()\n",
    "\n",
    "# def reduce_group(grps):\n",
    "#     use = []\n",
    "#     for g in grps:\n",
    "#         mx = 0; vx = g[0]\n",
    "#         for gg in g:\n",
    "#             n = df_train[gg].nunique()\n",
    "#             if n>mx:\n",
    "#                 mx = n\n",
    "#                 vx = gg\n",
    "#             #print(str(gg)+'-'+str(n),', ',end='')\n",
    "#         use.append(vx)\n",
    "#         #print()\n",
    "#     print('Use these',use)\n",
    "#     return use\n",
    "\n",
    "# def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "#     # 计算列之间的相关性\n",
    "#     correlation_matrix = matrix.corr()\n",
    "\n",
    "#     # 分组列\n",
    "#     groups = []\n",
    "#     remaining_cols = list(matrix.columns)\n",
    "#     while remaining_cols:\n",
    "#         col = remaining_cols.pop(0)\n",
    "#         group = [col]\n",
    "#         correlated_cols = [col]\n",
    "#         for c in remaining_cols:\n",
    "#             if correlation_matrix.loc[col, c] >= threshold:\n",
    "#                 group.append(c)\n",
    "#                 correlated_cols.append(c)\n",
    "#         groups.append(group)\n",
    "#         remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "#     return groups\n",
    "\n",
    "# uses=[]\n",
    "# for k,v in nans_groups.items():\n",
    "#     if len(v)>1:\n",
    "#             Vs = nans_groups[k]\n",
    "#             #cross_features=list(combinations(Vs, 2))\n",
    "#             #make_corr(Vs)\n",
    "#             grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "#             use=reduce_group(grps)\n",
    "#             uses=uses+use\n",
    "#             #make_corr(use)\n",
    "#     else:\n",
    "#         uses=uses+v\n",
    "#     print('####### NAN count =',k)\n",
    "# print(uses)\n",
    "# print(len(uses))\n",
    "# uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "# print(len(uses))\n",
    "# df_train=df_train[uses]\n",
    "# # df_train.drop(['requesttype_4525192L_cnt','max_empl_employedtotal_800L_cnt', 'max_empl_industry_691L_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b29ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('../../dataset/depth_data_dash.parquet')\n",
    "\n",
    "categorical_features = df_train.select_dtypes(include='category').columns\n",
    "np.save('../../dataset/categorical_features_dash.npy', categorical_features)\n",
    "print(len(categorical_features))\n",
    "\n",
    "display(df_train.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226796a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T14:01:03.040467Z",
     "iopub.status.busy": "2024-05-21T14:01:03.040225Z",
     "iopub.status.idle": "2024-05-21T14:01:04.408800Z",
     "shell.execute_reply": "2024-05-21T14:01:04.407933Z"
    },
    "papermill": {
     "duration": 1.38077,
     "end_time": "2024-05-21T14:01:04.411091",
     "exception": false,
     "start_time": "2024-05-21T14:01:03.030321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "oof = df_train[['WEEK_NUM', 'target']]\n",
    "oof['probability'] = np.zeros(len(oof))\n",
    "display(oof)\n",
    "\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "# df_train, y = SMOTE().fit_resample(df_train, y)\n",
    "\n",
    "display(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70c76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T14:01:04.432922Z",
     "iopub.status.busy": "2024-05-21T14:01:04.432625Z",
     "iopub.status.idle": "2024-05-21T14:01:04.592844Z",
     "shell.execute_reply": "2024-05-21T14:01:04.591888Z"
    },
    "papermill": {
     "duration": 0.173686,
     "end_time": "2024-05-21T14:01:04.595170",
     "exception": false,
     "start_time": "2024-05-21T14:01:04.421484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b4b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T14:01:04.618241Z",
     "iopub.status.busy": "2024-05-21T14:01:04.617973Z"
    },
    "papermill": {
     "duration": 346.469156,
     "end_time": "2024-05-21T14:06:51.075331",
     "exception": false,
     "start_time": "2024-05-21T14:01:04.606175",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_split = 5\n",
    "cv = StratifiedGroupKFold(n_splits=n_split, shuffle=False)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,  \n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 2000,  \n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"sample_weight\":'balanced',\n",
    "    \"device\": \"cpu\", \n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "fitted_models = []\n",
    "cv_scores = []\n",
    "\n",
    "for idx_train, idx_valid in cv.split(df_train, y, groups=weeks):#   Because it takes a long time to divide the data set, \n",
    "    X_train, y_train = df_train.iloc[idx_train], y.iloc[idx_train]# each time the data set is divided, two models are trained to each other twice, which saves time.\n",
    "    X_valid, y_valid = df_train.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set = [(X_valid, y_valid)],\n",
    "        callbacks = [lgb.log_evaluation(200), lgb.early_stopping(100)] )\n",
    "    fitted_models.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    oof[idx_valid] = y_pred_valid\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"AVG CV AUC score: \", np.mean(cv_scores))\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac383876",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_idx = np.argmax(cv_scores)\n",
    "best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd4ca5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(fitted_models[best_idx], importance_type=\"split\", figsize=(10, 50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b35143",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(fitted_models, 'lgb_models.joblib')\n",
    "\n",
    "notebook_info = {\n",
    "    'notebook_start_time': start_time_kst,\n",
    "    'description': 'Add notebook info dict to store cols and cat_cols',\n",
    "    'cols': df_train.columns.to_list(),\n",
    "    'cat_cols': cat_cols,\n",
    "}\n",
    "joblib.dump(notebook_info, 'notebook_info.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac7e5a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee0769",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"AVG CV AUC score: \", np.mean(cv_scores))\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0485fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(\n",
    "            self,\n",
    "            oof: pd.DataFrame,\n",
    "            save_path: Optional[Path]=None\n",
    "        ):\n",
    "\n",
    "        self.oof = oof\n",
    "        self.save_path = save_path\n",
    "\n",
    "        assert 'WEEK_NUM' in self.oof.columns\n",
    "        assert 'target' in self.oof.columns\n",
    "        assert 'probability' in self.oof.columns\n",
    "\n",
    "    def plot_pred(self, is_log: bool=False) -> None:\n",
    "        _, ax = plt.subplots()\n",
    "        sns.histplot(data=self.oof, x='probability', hue='target', bins=50, ax=ax)\n",
    "        if is_log:\n",
    "            ax.set_yscale('log')\n",
    "        if self.save_path is not None:\n",
    "            plt.savefig(Path.joinpath(self.save_path, 'hist_pred.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc(self) -> None:\n",
    "        fpr, tpr, _ = roc_curve(self.oof['target'], self.oof['probability'])\n",
    "        _, ax = plt.subplots()\n",
    "        ax.plot(fpr, tpr, label=f'ROC curve (AUC = {auc(fpr, tpr):.2f})')\n",
    "        ax.plot([0, 1], [0, 1], linestyle='--', color='k', label='Random')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.legend()\n",
    "        if self.save_path is not None:\n",
    "            plt.savefig(Path.joinpath(self.save_path, 'roc_curve.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_gini(self) -> Tuple[pd.DataFrame, float]:\n",
    "        gini_per_week = (\n",
    "            self.oof.\n",
    "            groupby('WEEK_NUM')\n",
    "            .apply(\n",
    "                lambda g: 2 * roc_auc_score(g['target'], g['probability']) - 1,\n",
    "                include_groups=False\n",
    "            )\n",
    "        )\n",
    "        gini_per_week.name = 'gini'\n",
    "        gini_per_week = gini_per_week.reset_index().sort_values('WEEK_NUM')\n",
    "\n",
    "        linear_regression = LinearRegression()\n",
    "        linear_regression.fit(gini_per_week[['WEEK_NUM']], gini_per_week[['gini']])\n",
    "        a = linear_regression.coef_[0].item()\n",
    "        b = linear_regression.intercept_.item()\n",
    "\n",
    "        gini_per_week['regression'] = a * gini_per_week['WEEK_NUM'] + b\n",
    "        gini_per_week['residuals'] = gini_per_week['gini'] - gini_per_week['regression']\n",
    "        stability = gini_per_week['gini'].mean() + 88.0 * min([0, a]) - 0.5 * gini_per_week['residuals'].std()\n",
    "\n",
    "        _, ax = plt.subplots()\n",
    "        ax.scatter(gini_per_week['WEEK_NUM'], gini_per_week['gini'], alpha=0.5, label='Gini coefficient')\n",
    "        ax.plot(\n",
    "            a * np.arange(0, 92) + b,\n",
    "            label=f'y = {a:.4f}x + {b:.4f}',\n",
    "            color='tab:orange'\n",
    "        )\n",
    "        ax.set(\n",
    "            xlabel='WEEK_NUM',\n",
    "            ylabel='Gini coefficient',\n",
    "            ylim=[0, 1],\n",
    "            title='stability: {:.4f}'.format(stability)\n",
    "        )\n",
    "        ax.legend()\n",
    "        if self.save_path is not None:\n",
    "            plt.savefig(Path.joinpath(self.save_path, 'gini_weeks.png'))\n",
    "        plt.show()\n",
    "\n",
    "        outcome = pd.DataFrame([[stability, a, b]], columns=['stability', 'slope', 'intercept'])\n",
    "        return gini_per_week, outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d42c09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluater = Evaluator(oof.query('probability!=-1'))\n",
    "gini_per_week, outcome = evaluater.plot_gini()\n",
    "display(gini_per_week)\n",
    "print(outcome)\n",
    "\n",
    "logger.info(\n",
    "    f'stability: {outcome[\"stability\"].item()}\\n'\n",
    "    + f'slope: {outcome[\"slope\"].item()}\\n'\n",
    "    + f'intercept: {outcome[\"intercept\"].item()}\\n'\n",
    ")\n",
    "\n",
    "outcome.to_csv(paths.output_dir.joinpath('outcome.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 589.275388,
   "end_time": "2024-05-21T14:06:51.183095",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-21T13:57:01.907707",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
